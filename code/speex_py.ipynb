{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The echo canceller is based on the MDF algorithm described in:\n",
    "\n",
    "J. S. Soo, K. K. Pang Multidelay block frequency adaptive filter, \n",
    "IEEE Trans. Acoust. Speech Signal Process., Vol. ASSP-38, No. 2, \n",
    "February 1990.\n",
    "\n",
    "We use the Alternatively Updated MDF (AUMDF) variant. Robustness to \n",
    "double-talk is achieved using a variable learning rate as described in:\n",
    "\n",
    "Valin, J.-M., On Adjusting the Learning Rate in Frequency Domain Echo \n",
    "Cancellation With Double-Talk. IEEE Transactions on Audio,\n",
    "Speech and Language Processing, Vol. 15, No. 3, pp. 1030-1034, 2007.\n",
    "http://people.xiph.org/~jm/papers/valin_taslp2006.pdf\n",
    "\n",
    "There is no explicit double-talk detection, but a continuous variation\n",
    "in the learning rate based on residual echo, double-talk and background\n",
    "noise.\n",
    "\n",
    "Another kludge that seems to work good: when performing the weight\n",
    "update, we only move half the way toward the \"goal\" this seems to\n",
    "reduce the effect of quantization noise in the update phase. This\n",
    "can be seen as applying a gradient descent on a \"soft constraint\"\n",
    "instead of having a hard constraint.\n",
    "\n",
    "Notes for this file:\n",
    "\n",
    "\n",
    "## Usage\n",
    "\n",
    "- processor = MDF(Fs, frame_size, filter_length)\n",
    "- processor.main_loop(u, d)\n",
    "\n",
    "- Fs                  : sample rate\n",
    "- u                   : speaker signal, vector in range [-1; 1]\n",
    "- d                   : microphone signal, vector in range [-1; 1]\n",
    "- filter_length       : typically 250ms, i.e. 4096 @ 16k FS\n",
    "-                      must be a power of 2\n",
    "- frame_size          : typically 8ms, i.e. 128 @ 16k Fs\n",
    "-                      must be a power of 2\n",
    "\n",
    "Shimin Zhang <shmzhang@npu-aslp.org>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def float_to_short(x):\n",
    "    x = x*32768.0\n",
    "    x[x < -32767.5] = -32768\n",
    "    x[x > 32766.5] = 32767\n",
    "    x = np.floor(0.5+x)\n",
    "    return x\n",
    "\n",
    "class MDF:\n",
    "    def __init__(self, fs: int, frame_size: int, filter_length: int) -> None:\n",
    "        nb_mic = 1\n",
    "        nb_speakers = 1\n",
    "        self.K = nb_speakers\n",
    "        K = self.K\n",
    "        self.C = nb_mic\n",
    "        C = self.C\n",
    "\n",
    "        self.frame_size = frame_size\n",
    "        self.filter_length = filter_length\n",
    "        self.window_size = frame_size*2\n",
    "        N = self.window_size\n",
    "        self.M = int(np.fix((filter_length+frame_size-1)/frame_size))\n",
    "        M = self.M\n",
    "        self.cancel_count = 0\n",
    "        self.sum_adapt = 0\n",
    "        self.saturated = 0\n",
    "        self.screwed_up = 0\n",
    "\n",
    "        self.sampling_rate = fs\n",
    "        self.spec_average = (self.frame_size)/(self.sampling_rate)\n",
    "        self.beta0 = (2.0*self.frame_size)/self.sampling_rate\n",
    "        self.beta_max = (.5*self.frame_size)/self.sampling_rate\n",
    "        self.leak_estimate = 0\n",
    "\n",
    "        self.e = np.zeros((N, C),)\n",
    "        self.x = np.zeros((N, K),)\n",
    "        self.input = np.zeros((self.frame_size, C),)\n",
    "        self.y = np.zeros((N, C),)\n",
    "        self.last_y = np.zeros((N, C),)\n",
    "        self.Yf = np.zeros((self.frame_size+1, 1),)\n",
    "        self.Rf = np.zeros((self.frame_size+1, 1),)\n",
    "        self.Xf = np.zeros((self.frame_size+1, 1),)\n",
    "        self.Yh = np.zeros((self.frame_size+1, 1),)\n",
    "        self.Eh = np.zeros((self.frame_size+1, 1),)\n",
    "\n",
    "        self.X = np.zeros((N, K, M+1), dtype=complex)\n",
    "        self.Y = np.zeros((N, C), dtype=complex)\n",
    "        self.E = np.zeros((N, C), dtype=complex)\n",
    "        self.W = np.zeros((N, K, M, C), dtype=complex)\n",
    "        self.foreground = np.zeros((N, K, M, C), dtype=complex)\n",
    "        self.PHI = np.zeros((frame_size+1, 1),)\n",
    "        self.power = np.zeros((frame_size+1, 1),)\n",
    "        self.power_1 = np.ones((frame_size+1, 1),)\n",
    "        self.window = np.zeros((N, 1),)\n",
    "        self.prop = np.zeros((M, 1),)\n",
    "        self.wtmp = np.zeros((N, 1),)\n",
    "        self.window = .5-.5 * \\\n",
    "            np.cos(2*np.pi*(np.arange(1, N+1).reshape(-1, 1)-1)/N)\n",
    "        decay = np.exp(-2.4/M)\n",
    "        self.prop[0, 0] = .7\n",
    "        for i in range(1, M):\n",
    "            self.prop[i, 0] = self.prop[i-1, 0]*decay\n",
    "        self.prop = (.8 * self.prop)/np.sum(self.prop)\n",
    "\n",
    "        self.memX = np.zeros((K, 1),)\n",
    "        self.memD = np.zeros((C, 1),)\n",
    "        self.memE = np.zeros((C, 1),)\n",
    "        self.preemph = .9\n",
    "        if self.sampling_rate < 12000:\n",
    "            self.notch_radius = .9\n",
    "        elif self.sampling_rate < 24000:\n",
    "            self.notch_radius = .982\n",
    "        else:\n",
    "            self.notch_radius = .992\n",
    "        self.notch_mem = np.zeros((2*C, 1),)\n",
    "        self.adapted = 0\n",
    "        self.Pey = 1\n",
    "        self.Pyy = 1\n",
    "        self.Davg1 = 0\n",
    "        self.Davg2 = 0\n",
    "        self.Dvar1 = 0\n",
    "        self.Dvar2 = 0\n",
    "\n",
    "        self.beta = 1.0\n",
    "        self.T = 1.0\n",
    "    \n",
    "    def mdf_adjust_prop(self,):\n",
    "        N = self.window_size\n",
    "        M = self.M\n",
    "        C = self.C\n",
    "        K = self.K\n",
    "        prop = np.zeros((M, 1),)\n",
    "        for i in range(M):\n",
    "            tmp = 1\n",
    "            for chan in range(C):\n",
    "                for speak in range(K):\n",
    "                    tmp = tmp + np.sum(np.abs(self.W[:N//2+1, speak, i, chan])**2)\n",
    "            prop[i] = np.sqrt(tmp)\n",
    "        max_sum = np.maximum(prop, 1)\n",
    "        prop = prop + .1 * max_sum\n",
    "        prop_sum = 1 + np.sum(prop)\n",
    "        prop = 0.99*prop/prop_sum\n",
    "        return prop\n",
    "    \n",
    "    def filter_dc_notch16(self, mic, mem):\n",
    "        out = np.zeros_like(mic)\n",
    "        den2 = self.notch_radius**2 + 0.7 * \\\n",
    "            (1-self.notch_radius)*(1 - self.notch_radius)\n",
    "        for i in range(self.frame_size):\n",
    "            vin = mic[i]\n",
    "            vout = mem[0] + vin\n",
    "            mem[0] = mem[1] + 2*(-vin + self.notch_radius*vout)\n",
    "            mem[1] = vin - (den2*vout)\n",
    "            out[i] = self.notch_radius * vout\n",
    "        return out, mem\n",
    "    \n",
    "    def update_beta(self, x, bt, T):        \n",
    "        term1 = (1+bt)/(2*T)\n",
    "        term2 = (1-bt)/(2*T)\n",
    "                \n",
    "        grad = np.zeros_like(x)\n",
    "        \n",
    "        # boolean masks\n",
    "        mask1 = (abs(x) < term2) | (abs(x) > term1)\n",
    "        mask2 = (x >= -term1) & (x <= -term2)\n",
    "        mask3 = (x >= term2) & (x <= term1)\n",
    "        \n",
    "        # Apply the function for each condition\n",
    "        grad[mask1] = 0\n",
    "        \n",
    "        grad[mask2] = 0.5 - 1/np.pi * np.cos((2*T*x[mask2]*np.pi + np.pi)/(2*bt)) \\\n",
    "                            - (2*T*x[mask2] + 1)/(2*bt) * np.sin((2*T*x[mask2]*np.pi + np.pi)/(2*bt))\n",
    "        \n",
    "        grad[mask3] = -0.5 + 1/np.pi * np.cos((2*T*x[mask3]*np.pi - np.pi)/(2*bt)) \\\n",
    "                            + (2*T*x[mask3] - 1)/(2*bt) * np.sin((2*T*x[mask3]*np.pi - np.pi)/(2*bt))\n",
    "        \n",
    "        return grad\n",
    "        \n",
    "    def update_T(self, x, bt, T):    \n",
    "        # Calculate the boundaries for the conditions\n",
    "        term1 = (1+bt)/(2*T)\n",
    "        term2 = (1-bt)/(2*T)\n",
    "\n",
    "        grad = np.zeros_like(x)\n",
    "        # Create masks for each condition\n",
    "        mask1 = abs(x) < term2\n",
    "        mask2 = (x >= -term1) & (x <= -term2)\n",
    "        mask3 = (x >= term2) & (x <= term1)\n",
    "        mask4 = abs(x) > term1\n",
    "\n",
    "        # Apply the function for each condition\n",
    "        grad[mask1] = 2 * x[mask1]\n",
    "        grad[mask2] = x[mask2] + x[mask2] * np.sin((2*T*x[mask2]*np.pi - np.pi)/(2*bt))\n",
    "        grad[mask3] = x[mask3] - x[mask3] * np.sin((2*T*x[mask3]*np.pi - np.pi)/(2*bt))\n",
    "        grad[mask4] = 0\n",
    "        \n",
    "        return grad\n",
    "    \n",
    "    def F(self, x, bt, T):\n",
    "        term1 = (1+bt)/(2*T)\n",
    "        term2 = (1-bt)/(2*T)\n",
    "        \n",
    "        F_x = np.zeros_like(x)\n",
    "        \n",
    "        # boolean masks\n",
    "        mask1 = (x >= -term1) & (x < -term2)\n",
    "        mask2 = (x >= -term2) & (x < term2)\n",
    "        mask3 = (x >= term2) & (x < term1)  \n",
    "        \n",
    "        # Apply the transformations based on conditions\n",
    "        F_x[x < -term1] = -1\n",
    "        F_x[mask1] =   T*x[mask1] - (1-bt)/2 - (bt/np.pi) * np.cos((2*T*x[mask1]*np.pi + np.pi)/(2*bt))\n",
    "        F_x[mask2] = 2*T*x[mask2]\n",
    "        F_x[mask3] =   T*x[mask3] + (1-bt)/2 + (bt/np.pi) * np.cos((2*T*x[mask3]*np.pi - np.pi)/(2*bt))\n",
    "        F_x[x >= term1] = 1\n",
    "        \n",
    "        return F_x\n",
    "    \n",
    "    def speex_echo_cancellation_mdf(self, mic, far_end):\n",
    "        N = self.window_size\n",
    "        M = self.M\n",
    "        C = self.C\n",
    "        K = self.K\n",
    "\n",
    "        # beta, T =1.0, 1.0\n",
    "        # cross correlation, auto correlation\n",
    "        Pey_cur = 1\n",
    "        Pyy_cur = 1\n",
    "\n",
    "        out = np.zeros((self.frame_size, C),)\n",
    "        self.cancel_count += 1\n",
    "\n",
    "        # Step size for power update\n",
    "        ss = .35/M\n",
    "        ss_1 = 1 - ss\n",
    "\n",
    "        # Apply a notch filter to make sure DC doesn't end up causing problems\n",
    "        for chan in range(C):\n",
    "            self.input[:, chan], self.notch_mem[:, chan] = self.filter_dc_notch16(\n",
    "                mic[:, chan], self.notch_mem[:, chan])\n",
    "\n",
    "            # Apply pre-emphasis filter to mic signal\n",
    "            for i in range(self.frame_size):\n",
    "                tmp32 = self.input[i, chan] - \\\n",
    "                    (np.dot(self.preemph, self.memD[chan]))\n",
    "                self.memD[chan] = self.input[i, chan]\n",
    "                self.input[i, chan] = tmp32\n",
    "\n",
    "        # Update the far-end signal for each frame\n",
    "        for speak in range(K):\n",
    "            for i in range(self.frame_size):\n",
    "                self.x[i, speak] = self.x[i+self.frame_size, speak]\n",
    "                tmp32 = far_end[i, speak] - np.dot(self.preemph, self.memX[speak])\n",
    "                self.x[i+self.frame_size, speak] = tmp32\n",
    "                self.memX[speak] = far_end[i, speak]\n",
    "\n",
    "        # Shift old data to make room for new frame\n",
    "        self.X = np.roll(self.X, 1, axis=2)\n",
    "\n",
    "        # X = FFT(far-end signal x)\n",
    "        for speak in range(K):\n",
    "            self.X[:, speak, 0] = np.fft.fft(self.x[:, speak])/N\n",
    "        \n",
    "        \n",
    "        Sxx = 0 # Sum of far-end signal x's power\n",
    "        for speak in range(K):\n",
    "            Sxx = Sxx + np.sum(self.x[self.frame_size:, speak]**2)\n",
    "            self.Xf = np.abs(self.X[:self.frame_size+1, speak, 0])**2\n",
    "        Sff = 0 # Sum of mic signal f's power\n",
    "        for chan in range(C):\n",
    "            self.Y[:, chan] = 0\n",
    "            for speak in range(K):\n",
    "                for j in range(M):\n",
    "                    # Compute the echo estimate (convolution in frequency domain)\n",
    "                    # x_time = np.fft.ifft(self.X[:, speak, j]).real\n",
    "                    # x_transformed = self.F(x_time, self.beta, self.T)\n",
    "                    # X_transformed_freq = np.fft.fft(x_transformed)\n",
    "                    self.Y[:, chan] = self.Y[:, chan] + self.X[:,speak, j]*self.foreground[:, speak, j, chan]\n",
    "                    \n",
    "            # Compute the error signal in the time domain\n",
    "            self.e[:, chan] = np.fft.ifft(self.Y[:, chan]).real * N\n",
    "            self.e[:self.frame_size, chan] = self.input[:, chan] - self.e[self.frame_size:, chan]\n",
    "            Sff = Sff + np.sum(np.abs(self.e[:self.frame_size, chan])**2)\n",
    "    \n",
    "        # Adjust the adaptation proportion based on the error signal\n",
    "        if self.adapted:\n",
    "            self.prop = self.mdf_adjust_prop()\n",
    "        if self.saturated == 0:\n",
    "            # Update filter weights if the signal is not saturated\n",
    "            for chan in range(C):\n",
    "                for speak in range(K):\n",
    "                    for j in list(range(M)[::-1]):\n",
    "                        # x_time = np.fft.ifft(np.conj(self.X[:, speak, j+1])[:,None]).real\n",
    "                        # x_transformed = self.F(x_time, self.beta, self.T)\n",
    "                        # X_transformed_freq = np.fft.fft(x_transformed)\n",
    "                        # self.PHI = np.concatenate([self.power_1, self.power_1[-2:0:-1]], axis=0) * self.prop[j] * X_transformed_freq * self.E[:, chan][:,None]\n",
    "                        self.PHI = np.concatenate([self.power_1, self.power_1[-2:0:-1]], axis=0) * self.prop[j] * np.conj(self.X[:, speak, j+1])[:,None] * self.E[:, chan][:,None]\n",
    "                        self.W[:,speak,j,chan] = self.W[:,speak,j,chan]+self.PHI[:,0]\n",
    "                        \n",
    "                        # After calculating the echo estimate Y, update beta and T ##################################################################################\n",
    "                        # self.beta = self.update_beta(x_time, self.beta, self.T, self.E[:, chan][:,None], self.W[:,speak,j,chan])   \n",
    "                        # self.T    = self.update_T(   x_time, self.beta, self.T, self.E[:, chan][:,None], self.W[:,speak,j,chan])\n",
    "                        \n",
    "        else:\n",
    "            self.saturated -= 1 # reduce saturation counter\n",
    "\n",
    "        # Apply a time-domain constraint to the filter coefficients\n",
    "        for chan in range(C):\n",
    "            for speak in range(K):\n",
    "                for j in range(M):\n",
    "                    if j == 0 or (2+self.cancel_count) % (M-1) == j:\n",
    "                        self.wtmp = np.fft.ifft(self.W[:, speak, j, chan]).real\n",
    "                        self.wtmp[self.frame_size:N] = 0\n",
    "                        self.W[:, speak, j, chan] = np.fft.fft(self.wtmp) # W to freq domain\n",
    "\n",
    "        # Reset buffers for frequency domain variables\n",
    "        self.Yf = np.zeros((self.frame_size+1, 1),)\n",
    "        self.Rf = np.zeros((self.frame_size+1, 1),)\n",
    "        self.Xf = np.zeros((self.frame_size+1, 1),)\n",
    "\n",
    "        Dbf = 0  # Initialize double-talk power estimate\n",
    "        for chan in range(C):\n",
    "            self.Y[:, chan] = 0  # Reset the output buffer for the next pass\n",
    "            for speak in range(K):\n",
    "                for j in range(M):\n",
    "                    self.Y[:, chan] = self.Y[:, chan] + self.X[:, speak, j] * self.W[:, speak, j, chan]\n",
    "            # Compute the current output signal to time domain\n",
    "            self.y[:, chan] = np.fft.ifft(self.Y[:, chan]).real*N\n",
    "\n",
    "        # Initialize the sum of the error signal power\n",
    "        See = 0 \n",
    "        # Compute the error between the microphone and echo signals in time domain\n",
    "        for chan in range(C):\n",
    "            self.e[:self.frame_size, chan] = self.e[self.frame_size:N,chan] - self.y[self.frame_size:N, chan]\n",
    "            Dbf = Dbf + 10 + np.sum(np.abs(self.e[:self.frame_size, chan])**2)\n",
    "            self.e[:self.frame_size, chan] = self.input[:, chan] - self.y[self.frame_size:N, chan]\n",
    "            See = See + np.sum(np.abs(self.e[:self.frame_size, chan])**2)\n",
    "        \n",
    "        VAR1_UPDATE = .5\n",
    "        VAR2_UPDATE = .25\n",
    "        VAR_BACKTRACK = 4\n",
    "        MIN_LEAK = .005\n",
    "\n",
    "        # Update statistics for foreground filter adaptation\n",
    "        self.Davg1 = .6*self.Davg1 + .4*(Sff-See)\n",
    "        self.Dvar1 = .36*self.Dvar1 + .16*Sff*Dbf\n",
    "        self.Davg2 = .85*self.Davg2 + .15*(Sff-See)\n",
    "        self.Dvar2 = .7225*self.Dvar2 + .0225*Sff*Dbf\n",
    "        \n",
    "        # Determine if the foreground filter should be updated\n",
    "        update_foreground = 0\n",
    "        if (Sff-See)*abs(Sff-See) > (Sff*Dbf):\n",
    "            update_foreground = 1\n",
    "        elif (self.Davg1 * abs(self.Davg1) > (VAR1_UPDATE*self.Dvar1)):\n",
    "            update_foreground = 1\n",
    "        elif (self.Davg2 * abs(self.Davg2) > (VAR2_UPDATE*(self.Dvar2))):\n",
    "            update_foreground = 1\n",
    "\n",
    "        if update_foreground:\n",
    "            self.Davg1 = 0\n",
    "            self.Davg2 = 0\n",
    "            self.Dvar1 = 0\n",
    "            self.Dvar2 = 0\n",
    "            self.foreground = self.W\n",
    "            for chan in range(C):\n",
    "                self.e[self.frame_size:N, chan] = \\\n",
    "                    (self.window[self.frame_size:N][:,0] * self.e[self.frame_size:N, chan]) \\\n",
    "                    + (self.window[:self.frame_size][:,0] * self.y[self.frame_size:N, chan])\n",
    "        else:\n",
    "            reset_background = 0\n",
    "            if (-(Sff-See)*np.abs(Sff-See) > VAR_BACKTRACK*(Sff*Dbf)):\n",
    "                reset_background = 1\n",
    "            if ((-self.Davg1 * np.abs(self.Davg1)) > (VAR_BACKTRACK*self.Dvar1)):\n",
    "                reset_background = 1\n",
    "            if ((-self.Davg2 * np.abs(self.Davg2)) > (VAR_BACKTRACK*self.Dvar2)):\n",
    "                reset_background = 1\n",
    "\n",
    "            if reset_background:\n",
    "                self.W = self.foreground\n",
    "                for chan in range(C):\n",
    "\n",
    "                    self.y[self.frame_size:N, chan] = self.e[self.frame_size:N, chan]\n",
    "                    self.e[:self.frame_size, chan] = self.input[:,chan] - self.y[self.frame_size:N, chan]\n",
    "                See = Sff\n",
    "                self.Davg1 = 0\n",
    "                self.Davg2 = 0\n",
    "                self.Dvar1 = 0\n",
    "                self.Dvar2 = 0\n",
    "\n",
    "        # Cross-correlation\n",
    "        Sey = 0\n",
    "        Syy = 0\n",
    "        Sdd = 0\n",
    "\n",
    "        for chan in range(C):\n",
    "            for i in range(self.frame_size):\n",
    "                 # Calculate the residual signal after echo cancellation\n",
    "                tmp_out = self.input[i, chan] - self.e[i+self.frame_size, chan]\n",
    "                tmp_out = tmp_out + self.preemph * self.memE[chan]\n",
    "                \n",
    "                # Check for saturation in the microphone signal\n",
    "                if mic[i, chan] <= -32000 or mic[i, chan] >= 32000:\n",
    "                    if self.saturated == 0:\n",
    "                        self.saturated = 1\n",
    "                out[i, chan] = tmp_out[0]\n",
    "                self.memE[chan] = tmp_out\n",
    "\n",
    "            # Prepare error signal for next iteration\n",
    "            self.e[self.frame_size:N, chan] = self.e[:self.frame_size, chan]\n",
    "            self.e[:self.frame_size, chan] = 0\n",
    "            Sey = Sey + np.sum(self.e[self.frame_size:N, chan] * self.y[self.frame_size:N, chan])\n",
    "            Syy = Syy + np.sum(self.y[self.frame_size:N, chan]**2)\n",
    "            Sdd = Sdd + np.sum(self.input**2)\n",
    "\n",
    "            # Compute the FFT of the error signal to freq domain\n",
    "            self.E = np.fft.fft(self.e,axis=0) / N\n",
    "\n",
    "            # Compute the FFT of the output signal to freq domain\n",
    "            self.y[:self.frame_size, chan] = 0\n",
    "            self.Y = np.fft.fft(self.y,axis=0) / N\n",
    "            self.Rf = np.abs(self.E[:self.frame_size+1, chan])**2\n",
    "            self.Yf = np.abs(self.Y[:self.frame_size+1, chan])**2\n",
    "            \n",
    "        if not (Syy >= 0 and Sxx >= 0 and See >= 0):\n",
    "            self.screwed_up = self.screwed_up + 50\n",
    "            out = np.zeros_like(out)\n",
    "        elif Sff > Sdd + N * 10000:\n",
    "            self.screwed_up = self.screwed_up + 1\n",
    "        else:\n",
    "            self.screwed_up = 0\n",
    "            \n",
    "        # Full reset if too many errors have occurred\n",
    "        if self.screwed_up >= 50:\n",
    "            print(\"Screwed up, full reset\")\n",
    "            self.__init__(self.sampling_rate,\n",
    "                          self.frame_size, self.filter_length)\n",
    "\n",
    "        # Ensure See is large enough\n",
    "        See = max(See, N * 100)\n",
    "        for speak in range(K):\n",
    "            Sxx = Sxx + np.sum(self.x[self.frame_size:, speak]**2)\n",
    "            self.Xf = np.abs(self.X[:self.frame_size+1, speak, 0])**2\n",
    "        self.power = ss_1*self.power + 1 + ss*self.Xf[:,None]\n",
    "        \n",
    "        # Update the power estimate with a smoothing factor\n",
    "        Eh_cur = self.Rf - self.Eh\n",
    "        Yh_cur = self.Yf - self.Yh\n",
    "        Pey_cur = Pey_cur + np.sum(Eh_cur*Yh_cur)\n",
    "        Pyy_cur = Pyy_cur + np.sum(Yh_cur**2)\n",
    "        self.Eh = (1-self.spec_average)*self.Eh + self.spec_average*self.Rf\n",
    "        self.Yh = (1-self.spec_average)*self.Yh + self.spec_average*self.Yf\n",
    "        \n",
    "        # Compute the ratio of cross-power to power\n",
    "        Pyy = np.sqrt(Pyy_cur)\n",
    "        Pey = Pey_cur/Pyy\n",
    "        tmp32 = self.beta0*Syy\n",
    "        if tmp32 > self.beta_max*See:\n",
    "            tmp32 = self.beta_max*See\n",
    "        alpha = tmp32 / See\n",
    "        alpha_1 = 1 - alpha\n",
    "        self.Pey = alpha_1*self.Pey + alpha*Pey\n",
    "        self.Pyy = alpha_1*self.Pyy + alpha*Pyy\n",
    "        if self.Pyy < 1:\n",
    "            self.Pyy = 1\n",
    "        if self.Pey < MIN_LEAK * self.Pyy:\n",
    "            self.Pey = MIN_LEAK * self.Pyy\n",
    "        if self.Pey > self.Pyy:\n",
    "            self.Pey = self.Pyy\n",
    "        self.leak_estimate = self.Pey/self.Pyy\n",
    "        if self.leak_estimate > 16383:\n",
    "            self.leak_estimate = 32767\n",
    "            \n",
    "        # Calculate the ratio of echo reduction\n",
    "        RER = (.0001*Sxx + 3.*self.leak_estimate*Syy) / See\n",
    "        if RER < Sey*Sey/(1+See*Syy):\n",
    "            RER = Sey*Sey/(1+See*Syy)\n",
    "        if RER > .5:\n",
    "            RER = .5\n",
    "\n",
    "        # Check if the filter has adapted sufficiently\n",
    "        if (not self.adapted and self.sum_adapt > M and self.leak_estimate*Syy > .03*Syy):\n",
    "            self.adapted = 1\n",
    "\n",
    "        # Adjust the filter's power estimate based on the leak estimate\n",
    "        if self.adapted:\n",
    "            for i in range(self.frame_size+1):\n",
    "                r = self.leak_estimate*self.Yf[i]\n",
    "                e = self.Rf[i]+1\n",
    "                if r > .5*e:\n",
    "                    r = .5*e\n",
    "                r = 0.7*r + 0.3*(RER*e)\n",
    "                self.power_1[i] = (r/(e*self.power[i]+10))\n",
    "        else:\n",
    "            adapt_rate = 0\n",
    "            if Sxx > N * 1000:\n",
    "                tmp32 = 0.25 * Sxx\n",
    "                if tmp32 > .25*See:\n",
    "                    tmp32 = .25*See\n",
    "                adapt_rate = tmp32 / See\n",
    "            self.power_1 = adapt_rate/(self.power+10)\n",
    "            self.sum_adapt = self.sum_adapt+adapt_rate\n",
    "\n",
    "        # Shift the last output buffer to make room for the next frame\n",
    "        self.last_y[:self.frame_size] = self.last_y[self.frame_size:N]\n",
    "        if self.adapted:\n",
    "            self.last_y[self.frame_size:N] = mic-out\n",
    "        return out\n",
    "\n",
    "    def main_loop(self, u, d):\n",
    "        \"\"\"MDF core function\n",
    "            u (array): reference signal\n",
    "            d (array): microphone signal\n",
    "        \"\"\"\n",
    "        assert u.shape == d.shape\n",
    "        u = float_to_short(u)\n",
    "        d = float_to_short(d)\n",
    "\n",
    "        e = np.zeros_like(u)\n",
    "        y = np.zeros_like(u)\n",
    "        beta, T = 1.0, 1.0\n",
    "        mu_beta, mu_T = .01, .01\n",
    "        \n",
    "        end_point = len(u)\n",
    "        \n",
    "        for n in range(0, end_point, self.frame_size):\n",
    "            nStep = np.floor(n/self.frame_size) + 1\n",
    "            self.nStep = nStep\n",
    "            \n",
    "            # Break if the remaining samples are less than frame_size\n",
    "            if n+self.frame_size > end_point:\n",
    "                break\n",
    "            u_frame = u[n:n+self.frame_size]\n",
    "            d_frame = d[n:n+self.frame_size]\n",
    "            \n",
    "            u_frame = self.F(u_frame[:, None], self.beta, self.T)\n",
    "            \n",
    "            # AEC Processing\n",
    "            out = self.speex_echo_cancellation_mdf(d_frame[:, None], u_frame[:, None])[:,0]\n",
    "            \n",
    "            # append non-linearity\n",
    "            diff_beta = self.update_beta(u_frame, self.beta, self.T)\n",
    "            diff_T = self.update_T(u_frame, self.beta, self.T)\n",
    "            \n",
    "            phi_beta = np.dot(np.conj(self.wtmp[:self.frame_size]).flatten() * np.sign(self.e[self.frame_size:]), diff_beta)\n",
    "            phi_T = np.dot(np.conj(self.wtmp[:self.frame_size]).flatten() * np.sign(self.e[self.frame_size:]), diff_T)\n",
    "            \n",
    "            norm_u = np.linalg.norm(np.abs(u_frame)) + 1e-08\n",
    "            \n",
    "            beta = beta + (mu_beta/norm_u) * phi_beta\n",
    "            T = T + (mu_T/norm_u) * phi_T\n",
    "            \n",
    "            # Store the output and error signals\n",
    "            e[n:n+self.frame_size] = out\n",
    "            y[n:n+self.frame_size] = d_frame - out\n",
    "            \n",
    "        e = e/32768.0\n",
    "        y = y/32768.0\n",
    "        return e, y\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import librosa\n",
    "tmp, sr = sf.read(\"samples/input.wav\")\n",
    "mic = tmp[:, 0]\n",
    "ref = tmp[:, 2]\n",
    "\n",
    "\n",
    "processor = MDF(sr, 128, 1024)\n",
    "e, y = processor.main_loop(ref, mic)\n",
    "sf.write('speech_temp.wav', e, sr)\n",
    "sf.write('noise_temp.wav', y, sr)\n",
    "\n",
    "# Apply the function for each condit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactoring speex python"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LG_HnA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
